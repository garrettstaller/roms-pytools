{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e53333e1-5b6c-404a-8f58-05e9c169f2e7",
   "metadata": {},
   "source": [
    "### NC Join Adapted for Python .ipynb Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fb3ae3-ce8d-4b6b-ba4a-d9ee77c251ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- EDIT ----- #\n",
    "\n",
    "# Location of .nc files\n",
    "data_dir = '/path/to/data/'\n",
    "\n",
    "# Set the name of the output file where all netcdfs will be submitted \n",
    "odir     = '/path/to/store'\n",
    "ofname   = 'name.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7bc24-8128-493b-bdb8-317ca80438f6",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5899907-e0e5-4fb3-995b-313badee04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from netCDF4 import Dataset, num2date\n",
    "import glob as glob\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing \n",
    "from multiprocessing import Process, Pool\n",
    "start_run = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c28c2-8cf0-46d5-9a03-a40956f24230",
   "metadata": {},
   "source": [
    "#### Making list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08baf5f-b8ab-40bb-854c-63ce4f521cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gstaller/ucla-roms/Examples/Flux_frc/Flux_frc_new_rst.20121209133515.5.nc\n"
     ]
    }
   ],
   "source": [
    "# Using provided locations make a list of all netcdf files \n",
    "files = glob.glob(data_dir + '*.nc')\n",
    "\n",
    "# Index out last file \n",
    "fname = files[-1]\n",
    "print(fname)\n",
    "\n",
    "# Dataset from last netcdf file in provided directory\n",
    "nc = Dataset(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291b9e5-9c94-4f6f-b7a1-df6ece4c4621",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089f9c8b-8218-485d-b5e7-6ecdd32ef47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Variable \"ocean_time\"\n",
      "Added Variable \"time_step\" with dimensions (1, 6) as ('time', 'auxil')\n",
      "Added Variable \"zeta\" with dimensions (1, 101, 201) as ('time', 'eta_rho', 'xi_rho')\n",
      "Added Variable \"ubar\" with dimensions (1, 101, 200) as ('time', 'eta_rho', 'xi_u')\n",
      "Added Variable \"vbar\" with dimensions (1, 100, 201) as ('time', 'eta_v', 'xi_rho')\n",
      "Added Variable \"u\" with dimensions (1, 50, 101, 200) as ('time', 's_rho', 'eta_rho', 'xi_u')\n",
      "Added Variable \"v\" with dimensions (1, 50, 100, 201) as ('time', 's_rho', 'eta_v', 'xi_rho')\n",
      "Added Variable \"temp\" with dimensions (1, 50, 101, 201) as ('time', 's_rho', 'eta_rho', 'xi_rho')\n",
      "Added Variable \"salt\" with dimensions (1, 50, 101, 201) as ('time', 's_rho', 'eta_rho', 'xi_rho')\n",
      "Added Variable \"DU_avg2\" with dimensions (1, 101, 200) as ('time', 'eta_rho', 'xi_u')\n",
      "Added Variable \"DV_avg2\" with dimensions (1, 100, 201) as ('time', 'eta_v', 'xi_rho')\n",
      "Added Variable \"DU_avg_bak\" with dimensions (1, 101, 200) as ('time', 'eta_rho', 'xi_u')\n",
      "Added Variable \"DV_avg_bak\" with dimensions (1, 100, 201) as ('time', 'eta_v', 'xi_rho')\n",
      "Added Variable \"hbls\" with dimensions (1, 101, 201) as ('time', 'eta_rho', 'xi_rho')\n",
      "Added Variable \"hbbl\" with dimensions (1, 101, 201) as ('time', 'eta_rho', 'xi_rho')\n"
     ]
    }
   ],
   "source": [
    "# nvars is used to make an empty array for logicals, with a T/F for each variable\n",
    "# in the netcdf when filled.\n",
    "nvars         = len(nc.variables)\n",
    "partitionable = np.zeros(nvars, dtype=bool)\n",
    "\n",
    "output_file = odir+ofname\n",
    "# IF this file already exists and you wish to overwrite, use below function \n",
    "#os.remove(odir+ofname)\n",
    "# Make it into a dataset fomatted as a netcdf, such that data may be read in and written\n",
    "nco = Dataset(output_file, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "# Below is a loop that runs through each variable and adds it to our output file, with dimensions of all subdomains summed\n",
    "\n",
    "# Lets enumerate the dictionary so we may index out certain parts - Python's dictionaries are indexed by strings defaultly\n",
    "# We use items of our variables as this holds info on their name and dimension, we then assign variables\n",
    "for ivar, (vname, vinfo) in enumerate(nc.variables.items()):\n",
    "    vname      = vinfo.name                   # Name of the variable of focus\n",
    "    # NOTE: The way datasets load in information leaves spatial data last, that is x and y are the last and \n",
    "    #       second to last, respecitively. Therefore, when we need to grab information indexing the first \n",
    "    #       spatial term would be -1, making things less intuitive. So the dimensions and their names are\n",
    "    #       momentarily inverted such that x and y are now the first and second indices, making the code \n",
    "    #       more intuitive to the reader\n",
    "    vdim_names = vinfo.dimensions[::-1]       # Name of the dimensions\n",
    "    vdims      = np.array(vinfo.shape)[::-1]  # Size of each dimension\n",
    "    # Uncomment below to check each iteration of ivars variable and its dimensions \n",
    "    #print(ivar, '\\n', vname, '\\n', vdim_names, '\\n', vdims)\n",
    "    # check for dimensions, i.e. is it partitionable? Only multidimensional variables may be split into subdomains\n",
    "    if len(vdim_names) >= 2: \n",
    "        # Check if it is spatial data - xi and eta coordinates (x & y)\n",
    "        # the in operand simply confirms whether a string contains the part we specify\n",
    "        if 'xi' in vdim_names[0] and 'eta' in vdim_names[1]:\n",
    "            partitionable[ivar] = 1 # since partitionable is set to bool, 1 corresponds to true! \n",
    "            # We simply save that and move on to making empty space in a new netcdf \n",
    "            # The first step is grabbing the partition of the final file. fname, and adding our variables length \n",
    "            partition = nc.partition\n",
    "            # We add our dimensions to the final file, subtracting one, to get new dimensions that are the \n",
    "            # size of the desired joined output file\n",
    "            vdims[0] = vdims[0]+partition[2]-1\n",
    "            vdims[1] = vdims[1]+partition[3]-1\n",
    "            # ROMS uses rho and u/v/w points, which do not align. Therefore we account for that below. by adjusting our \n",
    "            # gridding if the dimension names specify they are u/v/w, not rho!\n",
    "            if \"xi_u\" in vdim_names[0]:\n",
    "                vdims[0] = vdims[0] - 1\n",
    "            if \"eta_v\" in vdim_names[1]:\n",
    "                vdims[1] = vdims[1] - 1\n",
    "        # Now allocate dimenions\n",
    "        # this is done as a try statement, as the function used can only make dimensions once.\n",
    "        # It is located here as the dimensions may change - per above - and thus need to correpsond with the right dimension\n",
    "        for l in range(len(vdims)):\n",
    "            try:\n",
    "                nco.createDimension(vdim_names[l], vdims[l])\n",
    "            except:\n",
    "                pass\n",
    "        # And add them to a variable\n",
    "        # Since we reversed our dimensions and names to make indexing more intuitive, we add to our variable from the \n",
    "        # end of vdims to the zeroth index. Putting dimensions back in order from the reference file used here. \n",
    "        if len(vdims) == 2:\n",
    "            nco.createVariable(vname, vinfo.datatype, (vdim_names[1], vdim_names[0])) \n",
    "            print(f'Added Variable \"{vname}\" with dimensions {vdims[1], vdims[0]} as {vdim_names[1], vdim_names[0]}')\n",
    "        elif len(vdims) == 3:\n",
    "            nco.createVariable(vname, vinfo.datatype, (vdim_names[2], vdim_names[1], vdim_names[0]), \\\n",
    "                               compression='zlib') #,significant_digits=4)\n",
    "            print((f'Added Variable \"{vname}\" with dimensions {vdims[2], vdims[1], vdims[0]}')+ \\\n",
    "                  (f' as {vdim_names[2], vdim_names[1], vdim_names[0]}'))\n",
    "        else:\n",
    "            nco.createVariable(vname, vinfo.datatype, (vdim_names[3], vdim_names[2], vdim_names[1], vdim_names[0]), \\\n",
    "                               compression='zlib') #, significant_digits=4)\n",
    "            print((f'Added Variable \"{vname}\" with dimensions {vdims[3], vdims[2], vdims[1], vdims[0]}')+ \\\n",
    "                 (f' as {vdim_names[3], vdim_names[2], vdim_names[1], vdim_names[0]}'))\n",
    "    # For one dimensional products\n",
    "    else:\n",
    "        nco.createDimension(vname, None)      \n",
    "        nco.createVariable(vname, vinfo.datatype) \n",
    "        print(f'Added Variable \"{vname}\"')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4bdaf2-e51c-430d-935e-266bca75a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable ocean_time added at: 0.02 seconds \n",
      "\n",
      "Variable time_step added at: 0.04 seconds \n",
      "\n",
      "Variable zeta added at: 0.15 seconds \n",
      "\n",
      "Variable ubar added at: 0.22 seconds \n",
      "\n",
      "Variable vbar added at: 0.30 seconds \n",
      "\n",
      "Variable u added at: 0.42 seconds \n",
      "\n",
      "Variable v added at: 0.53 seconds \n",
      "\n",
      "Variable temp added at: 0.63 seconds \n",
      "\n",
      "Variable salt added at: 0.73 seconds \n",
      "\n",
      "Variable DU_avg2 added at: 0.78 seconds \n",
      "\n",
      "Variable DV_avg2 added at: 0.83 seconds \n",
      "\n",
      "Variable DU_avg_bak added at: 0.89 seconds \n",
      "\n",
      "Variable DV_avg_bak added at: 0.94 seconds \n",
      "\n",
      "Variable hbls added at: 1.00 seconds \n",
      "\n",
      "Variable hbbl added at: 1.05 seconds \n",
      "\n",
      "Total Time: 1.05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for ivar, (vname, vinfo) in enumerate(nco.variables.items()):\n",
    "    vname = vinfo.name\n",
    "    vdim_names = vinfo.dimensions\n",
    "    vdims = np.array(vinfo.shape)\n",
    "\n",
    "    if partitionable[ivar]:\n",
    "        fvar = np.zeros(vdims)\n",
    "        \n",
    "        for f in range(len(files)):\n",
    "            nc = Dataset(files[f])\n",
    "            llc = nc.partition\n",
    "\n",
    "            # Adjust llc as needed\n",
    "            if \"xi_u\" in vdim_names[-1]:\n",
    "                llc[2] = max(llc[2]-1, 1)\n",
    "            if 'eta_v' in vdim_names[-2]:\n",
    "                llc[3] = max(llc[3]-1, 1)\n",
    "\n",
    "            # Grab data to put into subdomain \n",
    "            data = nc.variables[vname][:]\n",
    "            dims = data.shape\n",
    "\n",
    "            # With the parts of the output file selected for current subdomian, add respective data            \n",
    "            if len(vdims) == 2:\n",
    "                fvar[llc[3]-1:llc[3] + (dims[-2]-1), llc[2]-1:llc[2] + (dims[-1]-1)] = data\n",
    "            elif len(vdims) == 3:\n",
    "                fvar[:, llc[3]-1:llc[3] + (dims[-2]-1), llc[2]-1:llc[2] + (dims[-1]-1)] = data\n",
    "            else:\n",
    "                fvar[:,:,llc[3]-1:llc[3] + (dims[-2]-1), llc[2]-1:llc[2] + (dims[-1]-1)] = data\n",
    "\n",
    "            print(f'{vname} - File Progress = {((f+1)/len(files))*100: .2f}%', end = '\\r')\n",
    "            \n",
    "            # Close current netcdf file \n",
    "            nc.close()\n",
    "\n",
    "        if len(vdims) == 2:\n",
    "            nco.variables[vname][:,:] = fvar\n",
    "        elif len(vdims) == 3:\n",
    "            nco.variables[vname][:,:,:] = fvar\n",
    "        else:\n",
    "            nco.variables[(vname)][:,:,:,:] = fvar\n",
    "        \n",
    "    else:\n",
    "        nc = Dataset(files[0])\n",
    "        data = nc.variables[(vname)] # Read data once\n",
    "        nco.variables[vname] = data\n",
    "        nc.close()\n",
    "\n",
    "    print(f'Variable {vname} added at: {time.time() - start:.2f} seconds \\n')\n",
    "\n",
    "print(f'Total Time: {time.time() - start:.2f}')\n",
    "\n",
    "# Now close the file since we are done editing it\n",
    "nco.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0a218-7e58-4cdb-8981-c13cc1d77eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
